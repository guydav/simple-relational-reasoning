{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "sys.path.append(os.path.abspath('../run'))\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.collections import PatchCollection\n",
    "\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fdff2a83390>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_relational_reasoning.datagen import *\n",
    "from simple_relational_reasoning import models\n",
    "\n",
    "import run\n",
    "from quinn_defaults import prettify_class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_MODELS_CONFIG_KEY = 'default'\n",
    "LARGER_MODELS_CONFIG_KEY = 'larger'\n",
    "MODEL_CONFIGURATIONS = {\n",
    "    DEFAULT_MODELS_CONFIG_KEY: {\n",
    "        models.CombinedObjectMLPModel: dict(embedding_size=8, prediction_sizes=[32, 32, 16]),\n",
    "        models.RelationNetModel: dict(embedding_size=8, object_pair_layer_sizes=[32], combined_object_layer_sizes=[32]),\n",
    "        models.TransformerModel: dict(embedding_size=8, transformer_mlp_sizes=[8, 8], mlp_sizes=[32, 32]),\n",
    "        # models.CNNModel: dict(conv_sizes=[8, 16], mlp_sizes=[16, 8],),\n",
    "        models.SimplifiedCNNModel: dict(conv_sizes=[8, 16], mlp_sizes=[16, 8],),\n",
    "        models.PrediNetModel: dict(key_size=4, num_heads=4, num_relations=4, output_hidden_size=16)\n",
    "    },\n",
    "    LARGER_MODELS_CONFIG_KEY: {\n",
    "        models.CombinedObjectMLPModel: dict(embedding_size=16, prediction_sizes=[64, 64, 32, 16]),\n",
    "        models.RelationNetModel: dict(embedding_size=16, object_pair_layer_sizes=[64, 32],\n",
    "                                      combined_object_layer_sizes=[64, 32]),\n",
    "        models.TransformerModel: dict(embedding_size=16, num_transformer_layers=3, num_heads=2,\n",
    "                                      transformer_mlp_sizes=[16, 16], mlp_sizes=[64, 32]),\n",
    "        # models.CNNModel: dict(conv_sizes=[8, 16, 32], mlp_sizes=[32, 32],),\n",
    "        models.SimplifiedCNNModel: dict(conv_sizes=[8, 16, 32], mlp_sizes=[32, 32],),\n",
    "        models.PrediNetModel: dict(key_size=8, num_heads=8, num_relations=8, output_hidden_size=32)\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFIGURATION NAME: default\n",
      "\tcombined-object-mlp: 1963\n",
      "\trelation-net: 1739\n",
      "\ttransformer: 1915\n",
      "\tsimplified-cnn: 1755\n",
      "\tpredi-net: 1891\n",
      "CONFIGURATION NAME: larger\n",
      "\tcombined-object-mlp: 7987\n",
      "\trelation-net: 8563\n",
      "\ttransformer: 8243\n",
      "\tsimplified-cnn: 8171\n",
      "\tpredi-net: 8387\n"
     ]
    }
   ],
   "source": [
    "REFERENCE_OBJECT_SIZE = 9\n",
    "TARGET_OBJECT_SIZE = 1\n",
    "ADD_NEITHER = True\n",
    "X_MAX = 25\n",
    "Y_MAX = 25\n",
    "SEED = 33\n",
    "PROP_TRAIN_REF_LOCATIONS = 0.90\n",
    "N_TRAIN_TARGET_OBJECT_LOCATIONS = 7\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "object_generator = ObjectGeneratorWithoutSize(SEED, REFERENCE_OBJECT_SIZE, TARGET_OBJECT_SIZE)\n",
    "\n",
    "spatial_dataset = False\n",
    "for config_name in MODEL_CONFIGURATIONS:\n",
    "    print(f'CONFIGURATION NAME: {config_name}')\n",
    "    for model_class, model_kwargs in MODEL_CONFIGURATIONS[config_name].items():\n",
    "        model_name = prettify_class_name(model_class)\n",
    "        \n",
    "        if 'simplified' in model_name.lower():\n",
    "            spatial_dataset = 'simplified'\n",
    "        else:\n",
    "            spatial_dataset = 'cnn' in model_name.lower()\n",
    "            \n",
    "        dataset = AboveBelowReferenceInductiveBias(object_generator, X_MAX, Y_MAX, SEED, \n",
    "                                           prop_train_reference_object_locations=PROP_TRAIN_REF_LOCATIONS,\n",
    "                                           n_train_target_object_locations=N_TRAIN_TARGET_OBJECT_LOCATIONS,\n",
    "                                           spatial_dataset=spatial_dataset)\n",
    "        \n",
    "        model = model_class(dataset, **model_kwargs)\n",
    "        \n",
    "        if spatial_dataset == 'simplified':\n",
    "            input_size = (BATCH_SIZE, 2, dataset.x_max, dataset.y_max)\n",
    "        elif spatial_dataset:\n",
    "            input_size = (BATCH_SIZE, model.object_size, dataset.x_max, dataset.y_max)\n",
    "        else:\n",
    "            input_size = (BATCH_SIZE, model.num_objects, model.object_size)\n",
    "        \n",
    "        print(f'\\t{model_name}: {sum([p.numel() for p in model.parameters()])}')\n",
    "        sample_input = torch.rand(input_size)\n",
    "        y = model(sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFIGURATION NAME: default\n",
      "\tcombined-object-mlp: 1971\n",
      "\trelation-net: 1747\n",
      "\ttransformer: 1923\n",
      "\tsimplified-cnn: 1755\n",
      "\tpredi-net: 939\n",
      "CONFIGURATION NAME: larger\n",
      "\tcombined-object-mlp: 8003\n",
      "\trelation-net: 8579\n",
      "\ttransformer: 8259\n",
      "\tsimplified-cnn: 8171\n",
      "\tpredi-net: 4563\n"
     ]
    }
   ],
   "source": [
    "REFERENCE_OBJECT_SIZE = 9\n",
    "TARGET_OBJECT_SIZE = 1\n",
    "ADD_NEITHER = True\n",
    "X_MAX = 25\n",
    "Y_MAX = 25\n",
    "SEED = 33\n",
    "PROP_TRAIN_REF_LOCATIONS = 0.90\n",
    "N_TRAIN_TARGET_OBJECT_LOCATIONS = 7\n",
    "\n",
    "object_generator = ObjectGeneratorWithSize(SEED, REFERENCE_OBJECT_SIZE, TARGET_OBJECT_SIZE)\n",
    "\n",
    "spatial_dataset = False\n",
    "for config_name in MODEL_CONFIGURATIONS:\n",
    "    print(f'CONFIGURATION NAME: {config_name}')\n",
    "    for model_class, model_kwargs in MODEL_CONFIGURATIONS[config_name].items():\n",
    "        model_name = prettify_class_name(model_class)\n",
    "        \n",
    "        if 'simplified' in model_name.lower():\n",
    "            spatial_dataset = 'simplified'\n",
    "        else:\n",
    "            spatial_dataset = 'cnn' in model_name.lower()\n",
    "            \n",
    "        dataset = AboveBelowReferenceInductiveBias(object_generator, X_MAX + 2, Y_MAX + 2, SEED, \n",
    "                                           prop_train_reference_object_locations=PROP_TRAIN_REF_LOCATIONS,\n",
    "                                           n_train_target_object_locations=N_TRAIN_TARGET_OBJECT_LOCATIONS,\n",
    "                                           spatial_dataset=spatial_dataset)\n",
    "        \n",
    "        model = model_class(dataset, **model_kwargs)\n",
    "        \n",
    "        if spatial_dataset == 'simplified':\n",
    "            input_size = (BATCH_SIZE, 2, dataset.x_max, dataset.y_max)\n",
    "        elif spatial_dataset:\n",
    "            input_size = (BATCH_SIZE, model.object_size, dataset.x_max, dataset.y_max)\n",
    "        else:\n",
    "            input_size = (BATCH_SIZE, model.num_objects, model.object_size)\n",
    "        \n",
    "        print(f'\\t{model_name}: {sum([p.numel() for p in model.parameters()])}')\n",
    "        \n",
    "        sample_input = torch.rand(input_size)\n",
    "        y = model(sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
